{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7de2c605-bb86-4759-bc75-04c34434c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|███████████████████████████████████████████████████████| 44/44 [06:55<00:00,  9.44s/batch, loss=0.354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████████████████████████| 44/44 [06:45<00:00,  9.21s/batch, loss=0.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.2767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|███████████████████████████████████████████████████████| 44/44 [06:20<00:00,  8.65s/batch, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|███████████████████████████████████████████████████████| 44/44 [06:23<00:00,  8.72s/batch, loss=0.191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████████████████████████| 44/44 [06:24<00:00,  8.75s/batch, loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|███████████████████████████████████████████████████████| 44/44 [06:22<00:00,  8.70s/batch, loss=0.093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████████████████████████████████████████████████| 44/44 [06:20<00:00,  8.66s/batch, loss=0.0773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████████████████████████████████████████████████| 44/44 [06:21<00:00,  8.67s/batch, loss=0.0723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████████████████████████████████████████████████| 44/44 [06:45<00:00,  9.21s/batch, loss=0.0722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:16<00:00,  8.57s/batch, loss=0.0523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:30<00:00,  8.87s/batch, loss=0.0292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:20<00:00,  8.65s/batch, loss=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:30<00:00,  8.87s/batch, loss=0.0482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████████████████████████████████████████████████| 44/44 [06:23<00:00,  8.72s/batch, loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:14<00:00,  8.51s/batch, loss=0.0902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:10<00:00,  8.42s/batch, loss=0.0422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:23<00:00,  8.71s/batch, loss=0.0241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████████████████████████████████████████████████| 44/44 [06:14<00:00,  8.51s/batch, loss=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████████████████████████████████████████████████| 44/44 [06:06<00:00,  8.32s/batch, loss=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|█████████████████████████████████████████████████████| 44/44 [06:21<00:00,  8.66s/batch, loss=0.0648]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.0648\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "# File paths for data\n",
    "bee_csv = \"bee1_detections.csv\"\n",
    "wasp_csv = \"wasp1_detections.csv\"\n",
    "bee_folder = \"kaggle_bee_vs_wasp/bee1\"\n",
    "wasp_folder = \"kaggle_bee_vs_wasp/wasp1\"\n",
    "\n",
    "# Custom dataset class for loading and processing bee/wasp images\n",
    "class BeeWaspDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_folder, transform=None, label=0):\n",
    "        \"\"\"\n",
    "        Initialize dataset with metadata and transformation\n",
    "        Args:\n",
    "            csv_file: Path to CSV file with bounding box info and filenames\n",
    "            img_folder: Path to the folder containing images\n",
    "            transform: Data transformations\n",
    "            label: Integer label for the class (0 for bee and 1 for wasp)\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "        self.label = label \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples in the dataset\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single data point based on index\n",
    "        Args:\n",
    "            idx: Index of the data point\n",
    "        Returns:\n",
    "            Transformed image tensor and its corresponding label\n",
    "        \"\"\"\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.img_folder, row['Filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Crop image based on bounding box\n",
    "        x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])\n",
    "        image = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "        # Transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label\n",
    "\n",
    "# Data transformations: resizing, normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and split datasets\n",
    "bee_dataset = BeeWaspDataset(bee_csv, bee_folder, transform=transform, label=0)\n",
    "wasp_dataset = BeeWaspDataset(wasp_csv, wasp_folder, transform=transform, label=1)\n",
    "\n",
    "# Combine datasets\n",
    "full_dataset = bee_dataset + wasp_dataset\n",
    "\n",
    "# Split dataset into training, testing, and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = int(0.1 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size - test_size\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2) \n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Update progress bar with loss\n",
    "        progress_bar.set_postfix(loss=running_loss/len(train_loader))\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d7eb6b5-0c14-4d28-9268-173f97fd2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to bee_wasp.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model's weights\n",
    "model_save_path = \"bee_wasp.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model weights saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b25e267-5bff-47a4-9b21-96481e561e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given DataLoader and calculate metrics\n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        data_loader: DataLoader for evaluation\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute performance metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='binary')\n",
    "    recall = recall_score(all_labels, all_predictions, average='binary')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary')\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(cm)\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    \"\"\"\n",
    "    Plot the confusion matrix as a heatmap\n",
    "    Args:\n",
    "        cm: Confusion matrix as a 2D array\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Bee\", \"Wasp\"], yticklabels=[\"Bee\", \"Wasp\"])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4278ab3-2b72-4060-acb8-c6f4867ae279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9017\n",
      "Precision: 0.8750\n",
      "Recall: 0.8615\n",
      "F1 Score: 0.8682\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
